{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from grace.io.image_dataset import mrc_reader, ImageGraphDataset\n",
    "from grace.napari.utils import EdgeColor\n",
    "from grace.base import GraphAttrs\n",
    "from grace.models.feature_extractor import resnet, FeatureExtractor\n",
    "from grace.utils.augment_image import RandomImageGraphRotate\n",
    "from grace.utils.augment_graph import RandomEdgeAdditionAndRemoval\n",
    "from grace.models.datasets import dataset_from_graph\n",
    "from grace.models.classifier import GCN\n",
    "from grace.training.train import train_model\n",
    "\n",
    "from grace.utils.augment_image import RandomEdgeCrop\n",
    "from torchvision.transforms import (\n",
    "    Resize,\n",
    "    Lambda,\n",
    "    Normalize,\n",
    "    RandomApply,\n",
    "    RandomAffine,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SAVE_DIR = '/Users/mfamili/work/exp_grace/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Compose(object):\n",
    "    def __init__(self, transforms):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, image, target):\n",
    "        for t in self.transforms:\n",
    "            image, target = t(image, target)\n",
    "        return image, target\n",
    "    \n",
    "def normalize8(I):\n",
    "    I = np.array(I)\n",
    "    mn = I.min()\n",
    "    mx = I.max()\n",
    "\n",
    "    mx -= mn\n",
    "\n",
    "    I = ((I - mn)/mx) * 255\n",
    "    return I.astype(np.uint8)\n",
    "\n",
    "def draw_graph(graph, ax, edge_color:str='cyan', node_color='teal'):\n",
    "\n",
    "    # node positions\n",
    "    pos = {\n",
    "        idx: (node[GraphAttrs.NODE_X], node[GraphAttrs.NODE_Y]) \n",
    "        for idx, node in graph.nodes(data=True)\n",
    "    }\n",
    "    #edge_gt = [data[GraphAttrs.EDGE_GROUND_TRUTH] for _,_,data in graph_data['graph'].edges(data=True)]\n",
    "    edge_colors = [edge_color]\n",
    "    node_colors = [node_color]\n",
    "\n",
    "    nx.draw(\n",
    "        graph, \n",
    "        ax=ax, \n",
    "        pos=pos, \n",
    "        #pos=pos,\n",
    "        with_labels=False, \n",
    "        # node_color=\"w\", \n",
    "        #node_size=32,\n",
    "        node_size=15,\n",
    "        edge_color=edge_colors,\n",
    "        node_color=node_colors,\n",
    "    )\n",
    "\n",
    "def show_image_and_graph(image, graph_data):\n",
    "\n",
    "    fig, axes = plt.subplots(1,3, figsize=(30, 10))\n",
    "\n",
    "    # node positions\n",
    "    pos = {\n",
    "        idx: (node[GraphAttrs.NODE_X], node[GraphAttrs.NODE_Y]) \n",
    "        for idx, node in graph_data['graph'].nodes(data=True)\n",
    "    }\n",
    "    #pos = {k: (pos[k][1], pos[k][0]) for k in pos}\n",
    "    #pos_flipped = {k: (pos[k][1],image.size()[0]-pos[k][0]) for k in pos}\n",
    "    pos_flipped = {k: (pos[k][0],image.size()[1]-pos[k][1]) for k in pos}\n",
    "    pos_ = [pos_flipped, pos]\n",
    "\n",
    "    # edge annotations\n",
    "    edge_gt = [data[GraphAttrs.EDGE_GROUND_TRUTH] for _,_,data in graph_data['graph'].edges(data=True)]\n",
    "    edge_colors = [EdgeColor[gt.name].value for gt in edge_gt]\n",
    "\n",
    "    node_colors = [\n",
    "        EdgeColor[node_attrs[GraphAttrs.NODE_GROUND_TRUTH].name].value \n",
    "        for _, node_attrs in graph_data['graph'].nodes(data=True)\n",
    "    ]\n",
    "\n",
    "    axes[1].set_aspect('equal')\n",
    "\n",
    "    for n,ax in enumerate(axes[1:]):\n",
    "        nx.draw(\n",
    "            graph_data['graph'], \n",
    "            ax=ax, \n",
    "            pos=pos_[n], \n",
    "            #pos=pos,\n",
    "            with_labels=False, \n",
    "            # node_color=\"w\", \n",
    "            node_size=10,\n",
    "            #node_size=2,\n",
    "            edge_color=edge_colors,\n",
    "            node_color=node_colors,\n",
    "        )\n",
    "\n",
    "    for ax in [axes[0], axes[2]]:\n",
    "        image = normalize8(image)\n",
    "        ax.imshow(image, cmap='gray')\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "    fig.suptitle(graph_data['metadata'][\"image_filename\"], y=0.95, fontsize=25)\n",
    "\n",
    "    return fig, axes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Image and Graph (Grace File)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGEPATH = \"/Users/mfamili/work/datasets/dataset_synthetic_grace/shape_stars/train\"\n",
    "GRACEPATH = \"/Users/mfamili/work/datasets/dataset_synthetic_grace/shape_stars/train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_graph_dataset = ImageGraphDataset(\n",
    "    image_dir=IMAGEPATH,\n",
    "    grace_dir=GRACEPATH,\n",
    "    image_filetype=\"mrc\",\n",
    "    transform=lambda x,y: (x,y),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Image and Graph (No Augmentations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, graph_data in image_graph_dataset:\n",
    "\n",
    "    show_image_and_graph(image, graph_data)\n",
    "    #plt.savefig(os.path.join(IMAGE_SAVE_DIR, 'full_image_raw'), bbox_inches='tight')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Image and Graph (Rotation Augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_graph_dataset = ImageGraphDataset(\n",
    "    image_dir=IMAGEPATH,\n",
    "    grace_dir=GRACEPATH,\n",
    "    image_filetype=\"mrc\",\n",
    "    transform=RandomImageGraphRotate(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, graph_data in image_graph_dataset:\n",
    "\n",
    "    show_image_and_graph(image, graph_data)\n",
    "    plt.savefig(os.path.join(IMAGE_SAVE_DIR, 'full_image_rotated'), bbox_inches='tight')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Image and Graph (Graph Augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_graph_dataset = ImageGraphDataset(\n",
    "    image_dir=IMAGEPATH,\n",
    "    grace_dir=GRACEPATH,\n",
    "    image_filetype=\"mrc\",\n",
    "    transform=RandomEdgeAdditionAndRemoval(annotation_mode='unknown', p_add=0.02, p_remove=0.02),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, graph_data in image_graph_dataset:\n",
    "\n",
    "    show_image_and_graph(image, graph_data)\n",
    "    plt.savefig(os.path.join(IMAGE_SAVE_DIR, 'full_image_graph_aug'), bbox_inches='tight')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Bounding Boxes (No Augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = FeatureExtractor(model=lambda x: x,\n",
    "                                     augmentations=lambda x: x)\n",
    "image_e, graph_data_e = feature_extractor(image, graph_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_graph_dataset = ImageGraphDataset(\n",
    "    image_dir=IMAGEPATH,\n",
    "    grace_dir=GRACEPATH,\n",
    "    image_filetype=\"mrc\",\n",
    "    transform=Compose([\n",
    "        feature_extractor,\n",
    "    ]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NODES = [150, 151, 153]\n",
    "\n",
    "fig, axes = plt.subplots(1, len(NODES), figsize=(30,10))\n",
    "\n",
    "for node, ax in enumerate(axes):\n",
    "\n",
    "    patch = graph_data_e['graph'].nodes(data=True)[NODES[node]][GraphAttrs.NODE_FEATURES]\n",
    "    ax.imshow(patch[0], cmap='gray')\n",
    "    ax.set_title(f\"Patch {NODES[node]}\", fontsize=30)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "fig.suptitle('Patches, No Augmentation', fontsize=40, x=.51)\n",
    "plt.savefig(os.path.join(IMAGE_SAVE_DIR, 'patches_raw'), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Bounding Boxes (Rotated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = FeatureExtractor(model=lambda x: x,\n",
    "                                     augmentations=lambda x: x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_graph_dataset = ImageGraphDataset(\n",
    "    image_dir=IMAGEPATH,\n",
    "    grace_dir=GRACEPATH,\n",
    "    image_filetype=\"mrc\",\n",
    "    transform=Compose([\n",
    "        RandomImageGraphRotate(),\n",
    "        feature_extractor,\n",
    "    ]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_e, graph_data_e in image_graph_dataset:\n",
    "\n",
    "    show_image_and_graph(image_e, graph_data_e)\n",
    "    plt.savefig(os.path.join(IMAGE_SAVE_DIR, 'full_image_rotated_'), bbox_inches='tight')\n",
    "\n",
    "    NUM_NODES = 3\n",
    "\n",
    "    fig, axes = plt.subplots(1, NUM_NODES, figsize=(30,10))\n",
    "    ax_n = 0\n",
    "    node = 150\n",
    "    node_chosen = 0\n",
    "\n",
    "    for node in [150,151,153]:\n",
    "    #while node_chosen < NUM_NODES:\n",
    "\n",
    "        patch = graph_data_e['graph'].nodes(data=True)[node][GraphAttrs.NODE_FEATURES]\n",
    "        '''if patch is None:\n",
    "            node +=1\n",
    "            continue'''\n",
    "\n",
    "        ax = axes[ax_n]\n",
    "        ax.imshow(patch[0], cmap='gray')\n",
    "        ax.set_title(f\"Patch {node}\", fontsize=30)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax_n += 1\n",
    "        node_chosen += 1\n",
    "        node +=1\n",
    "\n",
    "    fig.suptitle('Patches, Rotated', fontsize=40, x=.51)\n",
    "    plt.savefig(os.path.join(IMAGE_SAVE_DIR, 'patches_rotated'), bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply transforms one by one "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import torch\n",
    "for image, graph_data in image_graph_dataset:\n",
    "\n",
    "    image_a, graph_data_a = RandomImageGraphRotate()(image, graph_data)\n",
    "    #print(torch.equal(image, image_a))\n",
    "    #print(nx.utils.misc.graphs_equal(graph_data['graph'], graph_data_a['graph']))\n",
    "    image_a, graph_data_a = feature_extractor(image_a, graph_data_a)'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Bounding Boxes (Translate Augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentations = RandomApply(\n",
    "    [\n",
    "        #RandomEdgeCrop(max_fraction=0.1),\n",
    "        RandomAffine(\n",
    "            degrees=0,\n",
    "            translate=(0.2, 0.2),\n",
    "        ),\n",
    "    ],\n",
    "    p=1.,\n",
    ")\n",
    "\n",
    "feature_extractor = FeatureExtractor(model=lambda x: x,\n",
    "                                    augmentations=augmentations)\n",
    "\n",
    "image_graph_dataset = ImageGraphDataset(\n",
    "    image_dir=IMAGEPATH,\n",
    "    grace_dir=GRACEPATH,\n",
    "    image_filetype=\"mrc\",\n",
    "    transform=Compose([\n",
    "        feature_extractor,\n",
    "    ]),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NODES = [150, 151, 153]\n",
    "\n",
    "for image_e, graph_data_e in image_graph_dataset:\n",
    "\n",
    "    fig, axes = plt.subplots(1, len(NODES), figsize=(30,10))\n",
    "\n",
    "    for node, ax in enumerate(axes):\n",
    "\n",
    "        patch = graph_data_e['graph'].nodes(data=True)[NODES[node]][GraphAttrs.NODE_FEATURES]\n",
    "        ax.imshow(normalize8(patch[0]), cmap='gray')\n",
    "        ax.set_title(f\"Patch {NODES[node]}\", fontsize=30)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "    fig.suptitle('Patches, Translation Augmentation', fontsize=40, x=.51)\n",
    "    plt.savefig(os.path.join(IMAGE_SAVE_DIR, 'patches_translated'), bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Bounding Boxes (Translate & Rotation Augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentations = RandomApply(\n",
    "    [\n",
    "        #RandomEdgeCrop(max_fraction=0.1),\n",
    "        RandomAffine(\n",
    "            degrees=0,\n",
    "            translate=(0.2, 0.2),\n",
    "        ),\n",
    "    ],\n",
    "    p=1.,\n",
    ")\n",
    "\n",
    "feature_extractor = FeatureExtractor(model=lambda x: x,\n",
    "                                    augmentations=augmentations)\n",
    "\n",
    "image_graph_dataset = ImageGraphDataset(\n",
    "    image_dir=IMAGEPATH,\n",
    "    grace_dir=GRACEPATH,\n",
    "    image_filetype=\"mrc\",\n",
    "    transform=Compose([\n",
    "        RandomImageGraphRotate(),\n",
    "        feature_extractor,\n",
    "    ]),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NODES = [150, 151, 153]\n",
    "\n",
    "for image_e, graph_data_e in image_graph_dataset:\n",
    "\n",
    "    fig, axes = plt.subplots(1, len(NODES), figsize=(30,10))\n",
    "\n",
    "    for node, ax in enumerate(axes):\n",
    "\n",
    "        patch = graph_data_e['graph'].nodes(data=True)[NODES[node]][GraphAttrs.NODE_FEATURES]\n",
    "        ax.imshow(normalize8(patch[0]), cmap='gray')\n",
    "        ax.set_title(f\"Patch {NODES[node]}\", fontsize=30)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "    fig.suptitle('Patches, Translation & Rotation Augmentation', fontsize=40, x=.51)\n",
    "    plt.savefig(os.path.join(IMAGE_SAVE_DIR, 'patches_translated_rotated'), bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = FeatureExtractor(model=lambda x: x,\n",
    "                                     bbox_size=(150,150),\n",
    "                                     transforms=lambda x: x,\n",
    "                                     augmentations=lambda x: x,)\n",
    "image_graph_dataset = ImageGraphDataset(\n",
    "    image_dir=IMAGEPATH,\n",
    "    grace_dir=GRACEPATH,\n",
    "    image_filetype=\"mrc\",\n",
    "    transform=Compose([\n",
    "        feature_extractor,\n",
    "    ]),\n",
    ")\n",
    "\n",
    "SUBGRAPHS = [30]\n",
    "\n",
    "for img, gph in image_graph_dataset:\n",
    "    dataset = dataset_from_graph(gph['graph'],mode = \"sub\")\n",
    "    for s in SUBGRAPHS:\n",
    "\n",
    "        data = dataset[s]\n",
    "        #x = data.x[:,0,...] # (N, 224, 224)\n",
    "        x = data.x # (N, 224, 224)\n",
    "        img_size = x.size()[-2:]\n",
    "        box_coords = data.edge_attr\n",
    "        edges = data.edge_index\n",
    "\n",
    "        coords = np.array([[cor[1], cor[0]] for cor in box_coords])\n",
    "\n",
    "        FACTOR = 1\n",
    "        PADDING = 7\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(20,20))\n",
    "        max_width = max(coords[:,0]) - min(coords[:,0]) + img_size[0] + PADDING*2\n",
    "        max_height = max(coords[:,1]) - min(coords[:,1]) + img_size[1]\n",
    "        w = int(max_width*FACTOR - img_size[1]*(FACTOR-1)) + PADDING*2\n",
    "        h = int(max_height*FACTOR - img_size[0]*(FACTOR-1)) + PADDING*2\n",
    "        img = np.full((w,h), 255, dtype='uint8')\n",
    "\n",
    "        for node in range(x.size(0)):\n",
    "\n",
    "            pad = np.zeros((img_size[-2]+PADDING*2, img_size[-1]+PADDING*2))\n",
    "\n",
    "            coord = coords[node]\n",
    "            x_, y_ =  coord[0] - min(coords[:,0]), coord[1] - min(coords[:,1])\n",
    "            x_, y_ = x_*FACTOR + PADDING, y_*FACTOR + PADDING\n",
    "            x_box = slice(int(x_), int(x_ + img_size[0]))\n",
    "            y_box = slice(int(y_), int(y_ + img_size[1]))\n",
    "            img[int(x_-PADDING):int(x_+PADDING+img_size[0]), int(y_-PADDING):int(y_+PADDING+img_size[1])] = pad\n",
    "            img[x_box, y_box] = normalize8(x[node])\n",
    "\n",
    "            circle = patches.Circle(xy=[y_+img_size[1]/2, x_+img_size[0]/2], radius=7, facecolor='darkorange')\n",
    "            c = circle.get_facecolor()\n",
    "            ax.add_patch(circle)\n",
    "\n",
    "        for edge in range(edges.size(1)):\n",
    "\n",
    "            src_node, dst_node = edges[0,edge], edges[1,edge]\n",
    "            x_vals = [coords[src_node][0], coords[dst_node][0]]\n",
    "            y_vals = [coords[src_node][1], coords[dst_node][1]]\n",
    "            \n",
    "            x_vals = [i - min(coords[:,0]) for i in x_vals]\n",
    "            x_vals = [i*FACTOR + PADDING + img_size[0]/2 for i in x_vals]\n",
    "            \n",
    "            y_vals = [i - min(coords[:,1]) for i in y_vals]\n",
    "            y_vals = [i*FACTOR + PADDING + img_size[1]/2 for i in y_vals]\n",
    "\n",
    "            ax.plot(y_vals, x_vals, linewidth=3, color=c)\n",
    "\n",
    "        ax.imshow(img, cmap='gray')\n",
    "\n",
    "        ax.spines[['right', 'top', 'bottom', 'left']].set_visible(False)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "        plt.savefig(os.path.join(IMAGE_SAVE_DIR, f'subgraph_{s}_orange_150px_to_scale'), bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw Subgraph on Big Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, graph_data in image_graph_dataset:\n",
    "    1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subgraph = 30\n",
    "central_coords = data.pos[np.where(np.isclose(data.edge_attr, 0))[0][0]]\n",
    "\n",
    "for node, values in graph_data['graph'].nodes(data=True):\n",
    "    node_coords = np.array([values[GraphAttrs.NODE_X], values[GraphAttrs.NODE_Y]])\n",
    "    if np.allclose(central_coords, node_coords):\n",
    "        central_node = node\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(15, 15))\n",
    "\n",
    "draw_graph(graph_data['graph'], ax)\n",
    "draw_graph(nx.ego_graph(graph_data['graph'], central_node), ax, 'darkorange', 'darkorange')\n",
    "\n",
    "image = normalize8(image)\n",
    "ax.imshow(image, cmap='gray')\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "\n",
    "plt.savefig(os.path.join(IMAGE_SAVE_DIR, f'location_subgraph_{s}'), bbox_inches='tight')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up dataset\n",
    "IMAGEPATH = \"/Users/mfamili/work/datasets/dataset_synthetic_grace/shape_stars/train\"\n",
    "GRACEPATH =  \"/Users/mfamili/work/datasets/dataset_synthetic_grace/shape_stars/train\"\n",
    "\n",
    "feature_extractor = FeatureExtractor(model=lambda x: np.random.normal(size=x.size()[:-3]+(2,)),\n",
    "                                     bbox_size=(224,224),\n",
    "                                     augmentations=lambda x: x,)\n",
    "image_graph_dataset = ImageGraphDataset(\n",
    "    image_dir=IMAGEPATH,\n",
    "    grace_dir=GRACEPATH,\n",
    "    image_filetype=\"mrc\",\n",
    "    transform=Compose([\n",
    "        feature_extractor,\n",
    "    ]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img, gph in image_graph_dataset:\n",
    "    training_dataset = dataset_from_graph(gph['graph'], mode='sub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn = GCN(input_channels=2,\n",
    "          hidden_channels=[2],\n",
    "          node_output_classes=2,\n",
    "          edge_output_classes=2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''for data in training_dataset:\n",
    "    print(data)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#node_x, edge_x = gcn(data.x, data.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(node_x.size(), edge_x.size(), data.edge_label.size(), data.edge_index.size())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(training_dataset, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in loader:\n",
    "\n",
    "    print(batch)\n",
    "    print(batch.x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(gcn, training_dataset, epochs=10, \n",
    "            log_dir=os.path.join(IMAGE_SAVE_DIR, \"run_3\"), metrics=['accuracy', 'confusion_matrix'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grace_env",
   "language": "python",
   "name": "grace_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
