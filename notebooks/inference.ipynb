{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run inference on pre-trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import numpy.typing as npt\n",
    "from torch_geometric.data import Data\n",
    "from tqdm.auto import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grace.base import GraphAttrs\n",
    "from grace.io.image_dataset import ImageGraphDataset\n",
    "from grace.models.feature_extractor import FeatureExtractor\n",
    "from grace.models.datasets import dataset_from_graph\n",
    "from grace.evaluation.visualisation import plot_simple_graph\n",
    "from grace.evaluation.inference import GraphLabelPredictor\n",
    "from grace.evaluation.utils import plot_confusion_matrix_tiles\n",
    "\n",
    "from grace.evaluation.metrics_classifier import (\n",
    "    accuracy_metric, \n",
    "    confusion_matrix_metric, \n",
    "    areas_under_curves_metrics,\n",
    ")\n",
    "# from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read some real grace-annotated data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor_filename = \"/Users/kulicna/Desktop/classifier/extractor/resnet152.pt\"\n",
    "pre_trained_resnet = torch.load(extractor_filename)\n",
    "feature_extractor = FeatureExtractor(model=pre_trained_resnet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grace_path = \"/Users/kulicna/Desktop/dataset/shape_stars/train\"\n",
    "grace_path = \"/Users/kulicna/Desktop/dataset/shape_stars/infer\"\n",
    "dataset = ImageGraphDataset(\n",
    "    image_dir=grace_path, \n",
    "    grace_dir=grace_path, \n",
    "    transform=feature_extractor,\n",
    "    keep_node_unknown_labels=False, \n",
    "    keep_edge_unknown_labels=False, \n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image, graph_data = dataset[1]\n",
    "image, graph_data = dataset[0]\n",
    "\n",
    "G = graph_data[\"graph\"]\n",
    "image = image.numpy()\n",
    "annot = graph_data[\"annotation\"]\n",
    "G.number_of_nodes(), G.number_of_edges(), annot.shape, image.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = 5\n",
    "_, axes = plt.subplots(nrows=1, ncols=3, figsize=(shape*3, shape*1))\n",
    "\n",
    "plot_simple_graph(G, title=f\"Graph with {G.number_of_nodes()} nodes & {G.number_of_edges()} edges\", ax=axes[0])\n",
    "axes[0].imshow(image, cmap=\"binary_r\")\n",
    "axes[1].imshow(annot, cmap=\"binary_r\")\n",
    "axes[2].imshow(image, cmap=\"binary_r\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nominate a pre-trained GCN model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier_filename = \"/Users/kulicna/Desktop/classifier/runs/2023-09-07_17-07-08/classifier.pt\"\n",
    "# classifier_filename = \"/Users/kulicna/Desktop/classifier/runs/2023-09-07_17-15-47/classifier.pt\"\n",
    "classifier_filename = \"/Users/kulicna/Desktop/classifier/runs/2023-09-07_17-30-51/classifier.pt\"  # best Linear classifier\n",
    "# classifier_filename = \"/Users/kulicna/Desktop/classifier/runs/2023-09-08_15-11-58/classifier.pt\"  # bad GCN + Linear classifier\n",
    "\n",
    "pre_trained_gcn = torch.load(classifier_filename)\n",
    "pre_trained_gcn.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features are now automatically appended to the image - predict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GraphLabelPredictor(pre_trained_gcn).set_node_and_edge_probabilities(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.nodes[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now compute metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_true = [node[GraphAttrs.NODE_GROUND_TRUTH] for _, node in G.nodes(data=True)]\n",
    "node_pred = [node[GraphAttrs.NODE_PREDICTION][0] for _, node in G.nodes(data=True)]\n",
    "node_probabs = np.array([node[GraphAttrs.NODE_PREDICTION][1] for _, node in G.nodes(data=True)])\n",
    "\n",
    "edge_true = [edge[GraphAttrs.EDGE_GROUND_TRUTH] for _, _, edge in G.edges(data=True)]\n",
    "edge_pred = [edge[GraphAttrs.EDGE_PREDICTION][0] for _, _, edge in G.edges(data=True)]\n",
    "edge_probabs = np.array([edge[GraphAttrs.EDGE_PREDICTION][1] for _, _, edge in G.edges(data=True)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_acc, edge_acc = accuracy_metric(node_pred, edge_pred, node_true, edge_true)\n",
    "node_acc, edge_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "areas_fig = areas_under_curves_metrics(node_probabs, edge_probabs, node_true, edge_true, figsize=(10, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# figsize = (12, 12)\n",
    "# colormap = \"copper\"\n",
    "# confusion_matrix_plotting_data = [\n",
    "#     [node_pred, node_true, \"nodes\"], \n",
    "#     [edge_pred, edge_true, \"edges\"],\n",
    "# ]\n",
    "\n",
    "# _, axs = plt.subplots(2, 2, figsize=figsize)\n",
    "\n",
    "# for d, matrix_data in enumerate(confusion_matrix_plotting_data):\n",
    "#     for n, nrm in enumerate([None, \"true\"]):\n",
    "#         ConfusionMatrixDisplay.from_predictions(\n",
    "#             y_pred=matrix_data[0],\n",
    "#             y_true=matrix_data[1],\n",
    "#             normalize=nrm,\n",
    "#             ax=axs[d, n],\n",
    "#             cmap=colormap,\n",
    "#             display_labels=[\"TN\", \"TP\"],\n",
    "#             text_kw={\"fontsize\": \"large\"},\n",
    "#         )\n",
    "\n",
    "#         flag = \"Raw Counts\" if nrm is None else \"Normalised\"\n",
    "#         text = f\"{matrix_data[2].capitalize()} | {flag} Values\"\n",
    "#         axs[d, n].set_title(text)\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_whole_graph = dataset_from_graph(G, mode=\"whole\")\n",
    "data_whole_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chop off the last Linear layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_linear_layers_from_model(model: torch.nn.Module) -> torch.nn.Sequential:\n",
    "    \"\"\"Chops off last 2 Linear layers from the classifier to \n",
    "    access node embeddings learnt by the GCN classifier.\"\"\"\n",
    "\n",
    "    modules = list(pre_trained_gcn.children())[:-2]\n",
    "    node_emb_extractor = torch.nn.Sequential(*modules)\n",
    "    for p in node_emb_extractor.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "    return node_emb_extractor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_emb_extractor = drop_linear_layers_from_model(model=pre_trained_gcn)\n",
    "node_emb_extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions_for_data_batches(\n",
    "    model: torch.nn.Module, \n",
    "    data_batches: list[Data],\n",
    ") -> tuple[torch.Tensor]:\n",
    "\n",
    "    node_softmax_preds = []\n",
    "    edge_softmax_preds = []\n",
    "    node_argmax_preds = []\n",
    "    edge_argmax_preds = []\n",
    "    node_labels = []\n",
    "    edge_labels = []\n",
    "\n",
    "    # Predict labels from sub-graph:\n",
    "    for data in tqdm(data_batches, desc=\"Predicting for the entire graph: \"):\n",
    "\n",
    "        # Get the ground truth labels:\n",
    "        node_labels.extend(data.y)\n",
    "        edge_labels.extend(data.edge_label)\n",
    "\n",
    "        # Get the model predictions:\n",
    "        node_x, edge_x = model.predict(x=data.x, edge_index=data.edge_index)\n",
    "        print (node_x.shape, edge_x.shape)\n",
    "\n",
    "        # Process node probs into classes predictions:\n",
    "        node_soft = node_x.softmax(dim=1)\n",
    "        node_softmax_preds.extend(node_soft)\n",
    "        node_arg = node_soft.argmax(dim=1).long()\n",
    "        node_argmax_preds.extend(node_arg)\n",
    "\n",
    "        # Process edge probs into classes predictions:\n",
    "        edge_soft = edge_x.softmax(dim=1)\n",
    "        edge_softmax_preds.extend(edge_soft)\n",
    "        edge_arg = edge_soft.argmax(dim=1).long()\n",
    "        edge_argmax_preds.extend(edge_arg)\n",
    "\n",
    "    # Stack the results:\n",
    "    node_softmax_preds = torch.stack(node_softmax_preds, axis=0)\n",
    "    edge_softmax_preds = torch.stack(edge_softmax_preds, axis=0)\n",
    "    node_argmax_preds = torch.stack(node_argmax_preds, axis=0)\n",
    "    edge_argmax_preds = torch.stack(edge_argmax_preds, axis=0)\n",
    "    node_labels = torch.stack(node_labels, axis=0)\n",
    "    edge_labels = torch.stack(edge_labels, axis=0)\n",
    "\n",
    "    print(node_softmax_preds.shape, node_argmax_preds.shape, node_labels.shape)\n",
    "    return node_softmax_preds, edge_softmax_preds, node_argmax_preds, edge_argmax_preds, node_labels, edge_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_results = get_predictions_for_data_batches(model=pre_trained_gcn, data_batches=data_whole_graph)\n",
    "node_probabs, edge_probabs, node_pred, edge_pred, node_true, edge_true = predicted_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(node_true)\n",
    "plt.plot(node_probabs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(edge_true)\n",
    "plt.plot(edge_probabs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Investigate\n",
    "\n",
    "# plt.scatter(x=node_pred, y=node_probabs[:, 0], color='firebrick', label='TN')\n",
    "# plt.scatter(x=node_pred, y=node_probabs[:, 1], color='limegreen', label='TP')\n",
    "# plt.title(\"Nodes\")\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# plt.scatter(x=range(node_probabs.shape[0]), y=node_probabs[:, 0], color='firebrick', label='TN')\n",
    "# plt.scatter(x=range(node_probabs.shape[0]), y=node_probabs[:, 1], color='limegreen', label='TP')\n",
    "# plt.title(\"Nodes\")\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# plt.scatter(x=edge_pred, y=edge_probabs[:, 0], color='firebrick', label='TN')\n",
    "# plt.scatter(x=edge_pred, y=edge_probabs[:, 1], color='limegreen', label='TP')\n",
    "# plt.title(\"Edges\")\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# plt.scatter(x=range(edge_probabs.shape[0]), y=edge_probabs[:, 0], color='firebrick', label='TN')\n",
    "# plt.scatter(x=range(edge_probabs.shape[0]), y=edge_probabs[:, 1], color='limegreen', label='TP')\n",
    "# plt.title(\"Edges\")\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation:\n",
    "### Simple metrics first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grace.evaluation.metrics_classifier import (\n",
    "    accuracy_metric, \n",
    "    confusion_matrix_metric, \n",
    "    areas_under_curves_metrics,\n",
    ")\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_acc, edge_acc = accuracy_metric(node_pred, edge_pred, node_true, edge_true)\n",
    "node_acc, edge_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cm, e_cm = confusion_matrix_metric(node_pred, edge_pred, node_true, edge_true, normalize=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cm, e_cm = confusion_matrix_metric(node_pred, edge_pred, node_true, edge_true, normalize=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "areas_fig = areas_under_curves_metrics(node_pred, edge_pred, node_true, edge_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Possibly, display all 4 confusion matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize = (12, 12)\n",
    "colormap = \"copper\"\n",
    "confusion_matrix_plotting_data = [\n",
    "    [node_pred, node_true, \"nodes\"], \n",
    "    [edge_pred, edge_true, \"edges\"],\n",
    "]\n",
    "\n",
    "_, axs = plt.subplots(2, 2, figsize=figsize)\n",
    "\n",
    "for d, matrix_data in enumerate(confusion_matrix_plotting_data):\n",
    "    for n, nrm in enumerate([None, \"true\"]):\n",
    "        ConfusionMatrixDisplay.from_predictions(\n",
    "            y_pred=matrix_data[0],\n",
    "            y_true=matrix_data[1],\n",
    "            normalize=nrm,\n",
    "            ax=axs[d, n],\n",
    "            cmap=colormap,\n",
    "            display_labels=[\"TN\", \"TP\"],\n",
    "            text_kw={\"fontsize\": \"large\"},\n",
    "        )\n",
    "\n",
    "        flag = \"Raw Counts\" if nrm is None else \"Normalised\"\n",
    "        text = f\"{matrix_data[2].capitalize()} | {flag} Values\"\n",
    "        axs[d, n].set_title(text)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Done!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grace-environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
