{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kulicna/anaconda3/envs/grace-environment/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kulicna/anaconda3/envs/grace-environment/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Users/kulicna/anaconda3/envs/grace-environment/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c106detail19maybe_wrap_dim_slowIxEET_S2_S2_b\n",
      "  Referenced from: <6A7076EE-85BD-37A7-BC35-1D4867F2B3D3> /Users/kulicna/anaconda3/envs/grace-environment/lib/python3.10/site-packages/torchvision/image.so\n",
      "  Expected in:     <F2FE5CF8-5B5B-3FAD-ADF8-C77D90F49FC9> /Users/kulicna/anaconda3/envs/grace-environment/lib/python3.10/site-packages/torch/lib/libc10.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from grace.models.feature_extractor import resnet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kulicna/anaconda3/envs/grace-environment/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /Users/kulicna/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:05<00:00, 9.02MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.nn.modules.container.Sequential,\n",
       " Sequential(\n",
       "   (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "   (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (2): ReLU(inplace=True)\n",
       "   (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "   (4): Sequential(\n",
       "     (0): BasicBlock(\n",
       "       (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "     (1): BasicBlock(\n",
       "       (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (5): Sequential(\n",
       "     (0): BasicBlock(\n",
       "       (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (downsample): Sequential(\n",
       "         (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "         (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "     (1): BasicBlock(\n",
       "       (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (6): Sequential(\n",
       "     (0): BasicBlock(\n",
       "       (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (downsample): Sequential(\n",
       "         (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "         (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "     (1): BasicBlock(\n",
       "       (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (7): Sequential(\n",
       "     (0): BasicBlock(\n",
       "       (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (downsample): Sequential(\n",
       "         (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "         (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "     (1): BasicBlock(\n",
       "       (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       " ))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rn = resnet(resnet_type=\"resnet18\")\n",
    "type(rn), rn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor_fn = \"/Users/kulicna/Desktop/classifier/extractor/resnet18.pt\"\n",
    "torch.save(rn, extractor_fn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the training log:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/Users/kulicna/Desktop/classifier/runs/2023-06-13_16-42-48/events.out.tfevents.1686670968.655-XJC7VW01FQ.97901.0',\n",
       " True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events_fn = \"/Users/kulicna/Desktop/classifier/runs/2023-06-13_16-42-48/events.out.tfevents.1686670968.655-XJC7VW01FQ.97901.0\"\n",
    "events_fn, os.path.isfile(events_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'images': ['confusion_matrix/train', 'confusion_matrix/test'], 'audio': [], 'histograms': [], 'scalars': [], 'distributions': [], 'tensors': [], 'graph': False, 'meta_graph': False, 'run_metadata': []}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Key Accuracy was not found in Reservoir'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(event_acc\u001b[39m.\u001b[39mTags())\n\u001b[1;32m      7\u001b[0m \u001b[39m# E. g. get wall clock, number of steps and value for a scalar 'Accuracy'\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m w_times, step_nums, vals \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mevent_acc\u001b[39m.\u001b[39mScalars(\u001b[39m'\u001b[39m\u001b[39mAccuracy\u001b[39m\u001b[39m'\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/envs/grace-env/lib/python3.11/site-packages/tensorboard/backend/event_processing/event_accumulator.py:603\u001b[0m, in \u001b[0;36mEventAccumulator.Scalars\u001b[0;34m(self, tag)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mScalars\u001b[39m(\u001b[39mself\u001b[39m, tag):\n\u001b[1;32m    592\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Given a summary tag, return all associated `ScalarEvent`s.\u001b[39;00m\n\u001b[1;32m    593\u001b[0m \n\u001b[1;32m    594\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[39m      An array of `ScalarEvent`s.\u001b[39;00m\n\u001b[1;32m    602\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 603\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscalars\u001b[39m.\u001b[39mItems(tag)\n",
      "File \u001b[0;32m~/anaconda3/envs/grace-env/lib/python3.11/site-packages/tensorboard/backend/event_processing/reservoir.py:110\u001b[0m, in \u001b[0;36mReservoir.Items\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mutex:\n\u001b[1;32m    109\u001b[0m     \u001b[39mif\u001b[39;00m key \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_buckets:\n\u001b[0;32m--> 110\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mKey \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m was not found in Reservoir\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m key)\n\u001b[1;32m    111\u001b[0m     bucket \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_buckets[key]\n\u001b[1;32m    112\u001b[0m \u001b[39mreturn\u001b[39;00m bucket\u001b[39m.\u001b[39mItems()\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Key Accuracy was not found in Reservoir'"
     ]
    }
   ],
   "source": [
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
    "event_acc = EventAccumulator(events_fn)\n",
    "event_acc.Reload()\n",
    "# Show all tags in the log file\n",
    "print(event_acc.Tags())\n",
    "\n",
    "# E. g. get wall clock, number of steps and value for a scalar 'Accuracy'\n",
    "w_times, step_nums, vals = zip(*event_acc.Scalars('Accuracy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Key confusion_matrix was not found in Reservoir'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m event_acc\u001b[39m.\u001b[39mScalars(tag\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mconfusion_matrix\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/grace-env/lib/python3.11/site-packages/tensorboard/backend/event_processing/event_accumulator.py:603\u001b[0m, in \u001b[0;36mEventAccumulator.Scalars\u001b[0;34m(self, tag)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mScalars\u001b[39m(\u001b[39mself\u001b[39m, tag):\n\u001b[1;32m    592\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Given a summary tag, return all associated `ScalarEvent`s.\u001b[39;00m\n\u001b[1;32m    593\u001b[0m \n\u001b[1;32m    594\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[39m      An array of `ScalarEvent`s.\u001b[39;00m\n\u001b[1;32m    602\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 603\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscalars\u001b[39m.\u001b[39mItems(tag)\n",
      "File \u001b[0;32m~/anaconda3/envs/grace-env/lib/python3.11/site-packages/tensorboard/backend/event_processing/reservoir.py:110\u001b[0m, in \u001b[0;36mReservoir.Items\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mutex:\n\u001b[1;32m    109\u001b[0m     \u001b[39mif\u001b[39;00m key \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_buckets:\n\u001b[0;32m--> 110\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mKey \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m was not found in Reservoir\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m key)\n\u001b[1;32m    111\u001b[0m     bucket \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_buckets[key]\n\u001b[1;32m    112\u001b[0m \u001b[39mreturn\u001b[39;00m bucket\u001b[39m.\u001b[39mItems()\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Key confusion_matrix was not found in Reservoir'"
     ]
    }
   ],
   "source": [
    "event_acc.Scalars(tag=\"confusion_matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (783400261.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[11], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    for summary in tf.train.summary_iterator(\"/path/to/log/file\"):\u001b[0m\n\u001b[0m                                                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "# from tensorflow.python.summary.summary_iterator import summary_iterator\n",
    "\n",
    "# for summary in tf.train.summary_iterator(\"/path/to/log/file\"):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grace-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
